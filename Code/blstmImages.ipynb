{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"blstmImages.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMOW3nny7UviEE/CS2cXeZD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YlcYeknqDazq","executionInfo":{"status":"ok","timestamp":1621427615760,"user_tz":-120,"elapsed":2149,"user":{"displayName":"Maria Natale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVUj-VNPg7oPZf-hbxFK9y-WScDBmQlvwJPmkWcg=s64","userId":"07543223348938372260"}},"outputId":"3e72562d-afd3-4099-f67b-6752e79fb11e"},"source":["!git clone https://github.com/maria-natale/ProgettoFVAB"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'ProgettoFVAB'...\n","remote: Enumerating objects: 152, done.\u001b[K\n","remote: Counting objects: 100% (152/152), done.\u001b[K\n","remote: Compressing objects: 100% (121/121), done.\u001b[K\n","remote: Total 152 (delta 48), reused 85 (delta 21), pack-reused 0\u001b[K\n","Receiving objects: 100% (152/152), 163.85 KiB | 1.26 MiB/s, done.\n","Resolving deltas: 100% (48/48), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Am9DepOEA5X","executionInfo":{"status":"ok","timestamp":1621427643158,"user_tz":-120,"elapsed":24964,"user":{"displayName":"Maria Natale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVUj-VNPg7oPZf-hbxFK9y-WScDBmQlvwJPmkWcg=s64","userId":"07543223348938372260"}},"outputId":"64fd1d58-80e2-4b98-be94-f907792f15e0"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VDIrcKS7GG4X","executionInfo":{"status":"ok","timestamp":1621428590073,"user_tz":-120,"elapsed":2026,"user":{"displayName":"Maria Natale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVUj-VNPg7oPZf-hbxFK9y-WScDBmQlvwJPmkWcg=s64","userId":"07543223348938372260"}},"outputId":"fd01d17c-c3d0-4658-ad79-a2f998700235"},"source":["!python \"/content/ProgettoFVAB/Code/create_dataset.py\""],"execution_count":13,"outputs":[{"output_type":"stream","text":["file_dataset/spagnolo_giapponese.csv\n","djs\n","100% 6335/6335 [00:00<00:00, 635607.02it/s]\n","100% 18200/18200 [00:00<00:00, 563317.88it/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Vma2HnR5zE1T","executionInfo":{"status":"ok","timestamp":1621428207076,"user_tz":-120,"elapsed":670,"user":{"displayName":"Maria Natale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVUj-VNPg7oPZf-hbxFK9y-WScDBmQlvwJPmkWcg=s64","userId":"07543223348938372260"}}},"source":["import os\n","import pandas as pd\n","import numpy as np\n","from keras.preprocessing import image\n","from tqdm import tqdm\n","from PIL import Image\n","\n","path_git = '/content/ProgettoFVAB'\n","filename = 'spagnolo_giapponese'\n","path_drive = '/content/drive/MyDrive/Casillo&Natale'\n","dataset_dir = 'dataset_Spagnolo_giapponese'\n","LANGUAGES = {4:'Spagnolo',\n","  7: 'Giapponese'}\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"XW10WMPAMlyv","executionInfo":{"status":"ok","timestamp":1621428208759,"user_tz":-120,"elapsed":665,"user":{"displayName":"Maria Natale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVUj-VNPg7oPZf-hbxFK9y-WScDBmQlvwJPmkWcg=s64","userId":"07543223348938372260"}}},"source":["train = pd.read_csv(os.path.join(path_drive, dataset_dir+'/etichette', filename+'ImmaginiClasse_train.csv'))\n","train.head()\n","test = pd.read_csv(os.path.join(path_drive, dataset_dir+'/etichette', filename+'ImmaginiClasse_test.csv'))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"gGUw8iTCokj0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sOBTRLBIoYoc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621428239425,"user_tz":-120,"elapsed":4263,"user":{"displayName":"Maria Natale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVUj-VNPg7oPZf-hbxFK9y-WScDBmQlvwJPmkWcg=s64","userId":"07543223348938372260"}},"outputId":"c1626807-e915-400e-8053-4ad9131962bf"},"source":[""],"execution_count":11,"outputs":[{"output_type":"stream","text":["Found 0 images belonging to 0 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WElaHnafM5Kd","outputId":"9b6335e7-26f3-4855-d72f-aa50aab62ecd"},"source":["\n","# creating an empty list\n","train_image = []\n","path_images_train = os.path.join(path_drive, dataset_dir, 'train')\n","\n","# for loop to read and store frames\n","#for i in tqdm(range(train.shape[0])):\n","for i in tqdm(range(80)):\n","  try:\n","    # loading the image and keeping the target size as (224,224,3)\n","    img = image.load_img(path_images_train+'/'+train['frame'][i], target_size=(224,224,3))\n","    # converting it to array\n","    img = image.img_to_array(img)\n","    # normalizing the pixel value\n","    img = img/255\n","    # appending the image to the train_image list\n","    train_image.append(img)\n","  except:\n","    print(\"corrotta\")\n","    \n","# converting the list to numpy array\n","x_train = np.array(train_image)\n","\n","# shape of the array\n","x_train.shape\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" 20%|██        | 14114/70350 [01:15<05:12, 179.68it/s]"],"name":"stderr"},{"output_type":"stream","text":["corrotta\n"],"name":"stdout"},{"output_type":"stream","text":[" 21%|██        | 14579/70350 [01:18<05:23, 172.18it/s]"],"name":"stderr"},{"output_type":"stream","text":["corrotta\n","corrotta\n"],"name":"stdout"},{"output_type":"stream","text":[" 21%|██        | 14654/70350 [01:18<05:28, 169.70it/s]"],"name":"stderr"},{"output_type":"stream","text":["corrotta\n"],"name":"stdout"},{"output_type":"stream","text":[" 28%|██▊       | 19753/70350 [03:04<103:33:47,  7.37s/it]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"k7bvDEUkPXq4"},"source":["# creating an empty list\n","test_image = []\n","path_images_test = os.path.join(path_drive, dataset_dir, 'test')\n","\n","# for loop to read and store frames\n","#for i in tqdm(range(test.shape[0])):\n","for i in tqdm(range(20)):\n","  try:\n","    # loading the image and keeping the target size as (224,224,3)\n","    img = image.load_img(path_images_test+'/'+test['frame'][i], target_size=(224,224,3))\n","    # converting it to array\n","    img = image.img_to_array(img)\n","    # normalizing the pixel value\n","    img = img/255\n","    # appending the image to the train_image list\n","    test_image.append(img)\n","  except:\n","    print(\"corrotta\")\n","    \n","# converting the list to numpy array\n","x_test = np.array(test_image)\n","\n","# shape of the array\n","x_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BUpRjKYuPtUP"},"source":["#y_train = train['language']\n","#y_test = test['language']\n","y_train = train.loc[:80, 1]\n","y_test = test.loc[:20, 1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V1rxKTXVg42S"},"source":["from keras.layers import Dropout\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Bidirectional\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error\n","\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","x_train = scaler.fit_transform(x_train)\n","x_test = scaler.fit_transform(x_test)\n","\n","\n","#Convert to numpy arrays\n","x_train, y_train = np.array(x_train), np.array(y_train)\n","#Reshape the data into 3-D array\n","x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n","\n","# Initialising the RNN\n","model = Sequential()\n","model.add(Bidirectional(LSTM(units = 100, return_sequences = True, input_shape = (x_train.shape[0], 1))))\n","model.add(Dropout(0.2))\n","\n","# Adding a second LSTM layer and Dropout layer\n","model.add(Bidirectional(LSTM(units = 100, return_sequences = True)))\n","model.add(Dropout(0.2))\n","\n","# Adding a third LSTM layer and Dropout layer\n","model.add(Bidirectional(LSTM(units = 100)))\n","model.add(Dropout(0.2))\n","\n","\n","\n","# Adding the output layer\n","# For Full connection layer we use dense\n","model.add(Dense(8, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y29VoMwGhCo6"},"source":["import tensorflow as tf\n","#compile and fit the model on 30 epochs\n","opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n","model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer=opt,\n","    metrics=['accuracy'],\n",")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VIAdx1iBhF4r"},"source":["model.fit(x_train, y_train, epochs = 2, batch_size = 50)\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g55g-EMyhH0L"},"source":["#Convert x_test to a numpy array \n","x_test = np.array(x_test)\n","\n","#Reshape the data into 3-D array\n","x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gfWvdpYRhPMV"},"source":["model.evaluate(x_test, y_test)"],"execution_count":null,"outputs":[]}]}