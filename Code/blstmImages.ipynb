{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b08bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import gc\n",
    "\n",
    "path_git = '/content/ProgettoFVAB'\n",
    "filename = 'all' #sostituisci con Landmark\n",
    "#filename = \"Landmark\"\n",
    "path_drive = 'C:/Users/CasaLab1/Desktop/Casillo&Natale/DATASET'\n",
    "dataset_dir = 'dataset_all_2'  #sostituisci con dataset_Landmark\n",
    "#dataset_dir = 'dataset_Landmark'\n",
    "LANGUAGES = {\n",
    "  1:'Italiano',\n",
    "  2:'Inglese',\n",
    "  3: 'Tedesco',\n",
    "  4:'Spagnolo',\n",
    "  5: 'Olandese',\n",
    "  6:'Russo',\n",
    "  7: 'Giapponese'}\n",
    "LANGUAGES_N = {\n",
    "    1:0,\n",
    "    2:1,\n",
    "    3:2,\n",
    "    4:3,\n",
    "    5:4,\n",
    "    6:5,\n",
    "    7:6\n",
    "}\n",
    "\"\"\"\n",
    "LANGUAGES = {\n",
    "    4:'Spagnolo',\n",
    "    7: 'Giapponese'}\n",
    "LANGUAGES_N = {\n",
    "    4:0,\n",
    "    7:1\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5a9cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = (112, 75)\n",
    "CHANNELS = 3\n",
    "NBFRAME =200\n",
    "BS = 4\n",
    "\n",
    "import glob\n",
    "import keras\n",
    "import keras_video\n",
    "import tensorflow\n",
    "\n",
    "def load_video(path, group):\n",
    "  # use sub directories names as classes\n",
    "  os.chdir(os.path.join(path, group))\n",
    "  classes = [i.split(os.path.sep)[-1] for i in glob.glob(os.path.join(path, group)+'/*')]\n",
    "  print(classes)\n",
    "  classes.sort()\n",
    "  # some global params\n",
    "  # pattern to get videos and classes\n",
    "  glob_pattern=path+'/'+group+'/{classname}/*.avi'\n",
    "  # for data augmentation\n",
    "  data_aug = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
    "      zoom_range=.1,\n",
    "      horizontal_flip=True,\n",
    "      rotation_range=8,\n",
    "      width_shift_range=.2,\n",
    "      height_shift_range=.2)\n",
    "  # Create video frame generator\n",
    "  val_shuffle = True\n",
    "  if group=='test':\n",
    "    val_shuffle = False\n",
    "  x = keras_video.VideoFrameGenerator(\n",
    "      #sequence_time=1,\n",
    "      classes=classes, \n",
    "      nb_frames=NBFRAME,\n",
    "      glob_pattern=glob_pattern,\n",
    "      shuffle=val_shuffle,\n",
    "      #method=keras_video.METHOD_ABS_DIFF, \n",
    "      batch_size=BS,\n",
    "      target_shape=SIZE,\n",
    "      nb_channel=CHANNELS,\n",
    "      use_frame_cache=True\n",
    "      #transformation=data_aug\n",
    "  )\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f7aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_video(os.path.join(path_drive, dataset_dir), 'train')\n",
    "validation = load_video(os.path.join(path_drive, dataset_dir), 'validation')\n",
    "test = load_video(os.path.join(path_drive, dataset_dir), 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f90bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, GlobalMaxPool2D\n",
    "def build_convnet(shape=(112, 75, 2)):\n",
    "    momentum = .9\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), input_shape=shape, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation=\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    \\\n",
    "    model.add(MaxPool2D())\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation=\"relu\"))\n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation=\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    \n",
    "    model.add(MaxPool2D())\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', activation=\"relu\"))\n",
    "    model.add(Conv2D(256, (3,3), padding='same', activation=\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    \n",
    "    model.add(MaxPool2D())\n",
    "    \n",
    "    model.add(Conv2D(512, (3,3), padding='same', activation=\"relu\"))\n",
    "    model.add(Conv2D(512, (3,3), padding='same', activation=\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    \n",
    "    # flatten...\n",
    "    model.add(GlobalMaxPool2D())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95d3cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import TimeDistributed, Dense, Dropout\n",
    "def action_model(shape=(5, 112, 112, 2), nbout=2):\n",
    "    # Create our convnet with (112, 112, 3) input shape\n",
    "    convnet = build_convnet(shape[1:])\n",
    "    \n",
    "    # then create our final model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # add the convnet with (5, 112, 112, 3) shape\n",
    "    model.add(TimeDistributed(convnet, input_shape=shape))\n",
    "    model.add(Bidirectional(LSTM(units =512, return_sequences = True, input_shape = (NBFRAME, 112*75*3))))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Adding a second LSTM layer and Dropout layer\n",
    "    model.add(Bidirectional(LSTM(units = 512, return_sequences = True)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Adding a third LSTM layer and Dropout layer\n",
    "    model.add(Bidirectional(LSTM(units = 512)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(nbout, activation='softmax'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d9ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSHAPE=(NBFRAME,) + SIZE + (CHANNELS,) # (5, 112, 112, 3)\n",
    "model = action_model(INSHAPE, len(LANGUAGES_N.keys()))\n",
    "optimizer = tensorflow.keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(\n",
    "    optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677ca928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "with tensorflow.device('/device:GPU:0'):\n",
    "    tensorflow.random.set_seed(42)\n",
    "    EPOCHS=50\n",
    "    class MyCustomCallback(tensorflow.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            gc.collect()\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss',\n",
    "            min_delta=0,\n",
    "            patience=80,\n",
    "            verbose=0, mode='auto')\n",
    "\n",
    "    history =model.fit_generator(\n",
    "        train,\n",
    "        validation_data=validation,\n",
    "        epochs=EPOCHS,\n",
    "        steps_per_epoch = len(train),\n",
    "        validation_steps= len(validation), \n",
    "        callbacks = [es]\n",
    "            #callbacks=[MyCustomCallback()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd0fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test, steps = len(test))\n",
    "predictions = predictions.argmax(axis = -1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaacc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true =[]\n",
    "x,y = test.next()\n",
    "for i in range(0,len(test)):\n",
    "    for j in range(BS):\n",
    "        y_true.append(y[j])\n",
    "    x,y = test.next()\n",
    "y_true = np.array(y_true).argmax(axis = -1)\n",
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb2c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = list(LANGUAGES.values())\n",
    "print(classification_report(y_true, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ed060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "valori=pd.crosstab(predictions, y_true)\n",
    "fig=plt.figure(figsize=(17,5))\n",
    "ax1=plt.subplot(121)\n",
    "ax1.set_title(\"Confusion Matrix\")\n",
    "sns.heatmap(valori,annot=True,cmap=\"Blues\",cbar=False)\n",
    "plt.xlabel(\"attuali\") \n",
    "plt.ylabel(\"predetti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f9dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in (list(LANGUAGES_N.keys())):\n",
    "  i = LANGUAGES_N[j]\n",
    "  TP= valori.iloc[i,i]\n",
    "  FP= valori.iloc[i,:].sum()-TP\n",
    "  FN= valori.iloc[:,i].sum()-TP\n",
    "  TN= valori.sum().sum() - TP - FP - FN\n",
    "  print(TP,FP,FN,TN)\n",
    "  #b=[[TP,FP],[FN,TN]]\n",
    "  b=[[TP,TN],[FP,FN]]\n",
    "  fig=plt.figure(figsize=(17,5))\n",
    "  ax1=plt.subplot(121)\n",
    "  sns.heatmap(b,annot=True,cmap=\"Blues\",cbar=False,fmt = \"g\")\n",
    "  #plt.xlabel(\"POSITIVI\") \n",
    "  #plt.ylabel(\"NEGATIVI\")\n",
    "  tick_marks = [0.5,1.5]\n",
    "  plt.title(LANGUAGES[j])\n",
    "  plt.xticks(tick_marks, [\"P\",\"N\",])\n",
    "  plt.yticks(tick_marks, [\"T\",\"F\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23e7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "vis_arr = multilabel_confusion_matrix(y_true, predictions, labels = list(LANGUAGES_N.values()))\n",
    "print(vis_arr)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in list(LANGUAGES_N.values()):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true == i, predictions == i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b053cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of a ROC curve for a specific class\n",
    "for i in list(LANGUAGES_N.values()):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b329ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac1241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
